{
"cells": [
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# Galaxy integration through API from FAIRDOM\n",
"\n",
"* Upload data from list of URLs\n",
"* Run workflow\n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"from bioblend import galaxy\n",
"from collections import OrderedDict\n",
"import json\n",
"import time\n",
"import re\n",
"f= open(\"dakey.txt\",\"r\")\n",
"assert(f)\n",
"galaxy_api_key = f.readline()\n",
"f.close()\n",
"galaxy_api_key = galaxy_api_key.rstrip()"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": []
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": []
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"f= open(\"JSON_INPUT\",\"r\")\n",
"#f= open(\"input.json\",\"r\")\n",
"json_input = json.load(f)\n",
"f.close()\n",
"json_input = json_input[\"marked\"]\n",
"json_input"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"def extract_url(s):\n",
"    e = re.compile(\".*href=\\\"(.*)\\\".*\");\n",
"    m = e.match(s)\n",
"    if(m):\n",
"        return_value = m.group(1)\n",
"        return return_value\n",
"    else:\n",
"        return s\n",
"    \n",
"r = extract_url('<a target=\"_blank\" href=\"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/002/ERR1059392/ERR1059392_1.fastq.gz\">ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/002/ERR1059392/ERR1059392_1.fastq.gz</a>')\n",
"r"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"samples = dict()\n",
"\n",
"for i in json_input.values():\n",
"    for j in range(1,len(json_input['0'][\"values\"])):\n",
"        sample_name = json_input['0'][\"values\"][j]\n",
"        step_name = json_input['1'][\"values\"][j]\n",
"        url = extract_url(json_input['2'][\"values\"][j])\n",
"        \n",
"        if (not(sample_name in samples.keys())):\n",
"            samples[sample_name] = dict();\n",
"        \n",
"        samples[sample_name][step_name] = url\n",
"    \n",
"samples"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"galaxy_config = {\n",
"    'url': 'https://usegalaxy.be',\n",
"    'api_key': galaxy_api_key # make an account on the Galaxy instance and then User - Preferences - Manage API key\n",
"}"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"fairdom_config = {\n",
"    'investigation' : '8-way RIL population', # Wolfgang\n",
"    #'investigation' : '8-way_RIL_population',# Frederik\n",
"    \n",
"    #'study' : 'RIL_8-way_growth_chamber',    \n",
"    #'assay' : 'RNA_seq_E-MTAB-3965',         \n",
"    'workflow' : 'Salmon_maize_paired' # name of the workflow, assumes there is only one with that name\n",
"}\n",
"\n",
"#samples = {\n",
"#    'RIL1' : \n",
"#        { \n",
"#            'forward' : 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/002/ERR1059392/ERR1059392_1.fastq.gz',\n",
"#            'reverse' : 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/002/ERR1059392/ERR1059392_2.fastq.gz',\n",
"#            #'phenotyping' : 'https://floppy.psb.ugent.be/index.php/s/0ZK7y1gZb26BAEg/download'\n",
"# }\n",
"#}"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"print(\"The list of URLs read from the data file:\\n\")\n",
"\n",
"for x in samples:\n",
"    print (x)\n",
"    for y in samples[x]:\n",
"        print (y +':'+ samples[x][y])"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## Connecting to Galaxy"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"* Connection to Galaxy\n",
"'url': 'https://usegalaxy.be',\n",
"'api_key': 'API_KEY' # make an account on the Galaxy instance and then User - Preferences - Manage API key\n",
"\n",
"* Info needed from FAIRDOM\n",
"investigation : 8-way RIL population\n",
"workflow : Salmon_maize_paired\n",
"\n",
"* Info on data "
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"gi = galaxy.GalaxyInstance(url=galaxy_config['url'], key=galaxy_config['api_key'])"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"\n",
"current_user = None\n",
"\n",
"success = False;\n",
"while(not success):\n",
"    try:\n",
"        print (\"Current user's information:\\n\")\n",
"        current_user = gi.users.get_current_user()\n",
"\n",
"        print (\"username:\" + current_user[\"username\"])\n",
"        print (\"email:\" + current_user[\"email\"])\n",
"        print (\"is_admin:\" + str(current_user[\"is_admin\"]))\n",
"        success = True\n",
"    except: \n",
"        print(\"Failed: \")\n",
"        time.sleep(60)\n",
"        success = False"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## Get the data and copy it to Galaxy"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"* I created a FAIRDOM data library where we will upload data, getting a link to it\n",
"* I need give an accouynt access to allow to write in this folder (feature not a bug)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"\n",
"#I created a FAIRDOM data library where we will upload data, getting a link to it\n",
"#I need give an accouynt access to allow to write in this folder (feature not a bug)\n",
"\n",
"success = False\n",
"\n",
"while(not success):\n",
"    try:\n",
"        library = gi.libraries.get_libraries(name = 'FAIRDOM')\n",
"        success = True\n",
"    except: \n",
"        print(\"Failed: \")\n",
"        time.sleep(60)\n",
"        success = False"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# If a folder with the investigation name already exist, \n",
"\n",
"success = False\n",
"\n",
"while(not success):\n",
"    try:\n",
"        root_folder = gi.libraries.get_folders(library[0]['id'])\n",
"        files = gi.libraries.show_library(library[0]['id'], contents=True)\n",
"\n",
"        investigation_present = False\n",
"\n",
"        investigation_library = \"\"\n",
"\n",
"        for file in files:\n",
"            if file['name'] == (\"/\" + fairdom_config['investigation']):\n",
"                investigation_present = True\n",
"                investigation_library = file['id']\n",
"\n",
"        if not investigation_present:\n",
"            print(\"A folder with the investigation name doesn't exist, create investigation!\")\n",
"            investigation_library =  gi.libraries.create_folder(library[0]['id'], fairdom_config['investigation'], description=None)[0]\n",
"        else:\n",
"            investigation_library =  gi.libraries.get_folders(library[0]['id'], name = \"/\" + fairdom_config['investigation'])[0]\n",
"            print(\"A folder with the investigation name already exist!\")\n",
"        success = True\n",
"\n",
"    except: \n",
"        print(\"Exception: \")\n",
"        time.sleep(60)\n",
"        success = False  \n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"uploads = {}\n",
"\n",
"\n",
"success = False\n",
"\n",
"while(not success):\n",
"    try:\n",
"        for sample in samples:\n",
"            print(sample)\n",
"            uploads[sample] = []\n",
"            for key, file in samples[sample].items():\n",
"                    print(file)\n",
"                    print(\"\\n\")\n",
"                    # does not check if file is present\n",
"                    file_present = False\n",
"                    for avail_file in files:\n",
"                        if avail_file['name'] == (\"/\" + fairdom_config['investigation'] + \"/\" + file):\n",
"                            print(\"file found: \")\n",
"                            print(avail_file)\n",
"                            print(\"\\n\")\n",
"                            uploads[sample].append(avail_file) \n",
"                            file_present = True\n",
"                            break\n",
"                    if not file_present :\n",
"                        # this gives url as filename, can be changed through update, not yet implemented\n",
"                        uploaded_file = gi.libraries.upload_file_from_url(library[0]['id'], \n",
"                             file_url = file, \n",
"                             folder_id=investigation_library['id'], \n",
"                             file_type='fastqsanger.gz',\n",
"                             #file_type='auto',                                             \n",
"                             #dbkey='?'\n",
"                            )\n",
"                        uploads[sample].append(uploaded_file[0])\n",
"        success = True\n",
"    except: \n",
"        print(\"Exception: \")\n",
"        time.sleep(60)\n",
"        success = False  "
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# to be improved, now waiting for all samples to be uploaded\n",
"not_yet_ready = True\n",
"errors = False\n",
"while not_yet_ready:\n",
"    for sample in samples:\n",
"        print(sample)\n",
"        \n",
"        for upload in uploads[sample]:\n",
"            success = False\n",
"            while(not success):\n",
"                try:\n",
"                    print(gi.libraries.show_dataset(library[0]['id'], upload['id'])['state'])\n",
"                    if gi.libraries.show_dataset(library[0]['id'], upload['id'])['state'] == 'ok':\n",
"                        not_yet_ready = False\n",
"                        # update_library_dataset(library[0]['id'], name=\"name_to_which_it_needs_to_be_changed\")\n",
"                    elif gi.libraries.show_dataset(library[0]['id'], upload['id'])['state'] == 'error':\n",
"                        not_yet_ready = False\n",
"                        errors = True\n",
"                    else: \n",
"                        not_yet_ready = True\n",
"                    success = True\n",
"                except:\n",
"                    success = False\n",
"if not_yet_ready:\n",
"    print(\"Waiting for upload\")\n",
"    time.sleep(60)            \n",
"print(\"The files are Ready !\")"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## Run workflow"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"#assumes a workflow with that name is present for the user\n",
"success = False\n",
"workflows = None\n",
"while(not success):\n",
"    try:\n",
"        workflows = gi.workflows.get_workflows(name = fairdom_config['workflow'], published=True)\n",
"        workflow = workflows[0]\n",
"        success = True\n",
"        print(\"Got workflow %s\" % fairdom_config['workflow'])\n",
"    except: \n",
"        print(\"Exception: \")\n",
"        time.sleep(60)\n",
"        success = False     "
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"invoked_workflows = {}\n",
"\n",
"for sample in samples:\n",
"    success = False\n",
"    while(not success):\n",
"        try:   \n",
"            success = True\n",
"            # assuming order forward - reverse and only for the first pair\n",
"            inputs = {}\n",
"            inputs[0] = { 'src':'ld', 'id':uploads[sample][0]['id'] }\n",
"            inputs[1] = { 'src':'ld', 'id':uploads[sample][1]['id'] }\n",
"\n",
"            invoked_workflow = gi.workflows.invoke_workflow(workflow['id'], \n",
"                                     inputs=inputs, \n",
"                                     import_inputs_to_history=True, \n",
"                                     history_name=sample)\n",
"            print(\"invoked workflow...\\n\")\n",
"            print(\"update time:\"+invoked_workflow[\"update_time\"])\n",
"            print(\"history id:\"+invoked_workflow[\"history_id\"])\n",
"            print(\"uuid:\"+invoked_workflow[\"uuid\"])\n",
"            print(\"state:\"+invoked_workflow[\"state\"])\n",
"            print(\"workflow id:\"+invoked_workflow[\"workflow_id\"])\n",
"            print(\"model_class:\"+invoked_workflow[\"model_class\"])\n",
"            print(\"id:\"+invoked_workflow[\"id\"])\n",
"            invoked_workflows[sample] = invoked_workflow\n",
"        except: \n",
"            print(\"Exception: \")\n",
"            time.sleep(60)\n",
"            success = False  \n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# needs to match annotation of workflow step labels\n",
"# assuming downloading one file per step\n",
"downloads = {\n",
"    'FastQC forward': {\n",
"        'type' : 'html_file',\n",
"        'filename_postfix' : 'fastqc_fw.zip' # zip file with a html (and other stuff) inside\n",
"    }, \n",
"    'FastQC reverse' : {\n",
"        'type' : 'text_file', # essentially same output as previous one, but text version\n",
"        'filename_postfix' : 'fastqc_rev.txt'\n",
"    }, \n",
"    'Salmon' : {\n",
"        'type' : 'output_quant',\n",
"        'filename_postfix' : 'counts.txt'\n",
"    }\n",
"}\n",
"\n",
"print(\"Downloading files:\\n\")\n",
"\n",
"for x in downloads:\n",
"    print (x)\n",
"    for y in downloads[x]:\n",
"        print (y +':'+ downloads[x][y])"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"all_ready = False\n",
"\n",
"while not all_ready:\n",
"    time.sleep(10)\n",
"    all_ready = True\n",
"    for sample in samples:\n",
"        print (sample)\n",
"        filename_prefix = fairdom_config['investigation'] + '_' + sample + '_' # to do: link with sample name, for now hardcoded\n",
"        #print (\"filename_prefix:\"+filename_prefix)\n",
"        #print (str(gi.workflows.show_invocation(invoked_workflows[sample]['workflow_id'], invoked_workflows[sample]['id'])['steps']))\n",
"        \n",
"        steps = None\n",
"        \n",
"        success = False\n",
"        while(not success):\n",
"            try:   \n",
"                success = True\n",
"                steps = gi.workflows.show_invocation(invoked_workflows[sample]['workflow_id'], invoked_workflows[sample]['id'])['steps']\n",
"            except:\n",
"                success = False\n",
"                time.sleep(10)\n",
"        \n",
"        for step in steps:\n",
"            print(\"steps: %s\" % step['job_id'])\n",
"            if step['job_id']: # input does not have job_id\n",
"                try:\n",
"                    state = gi.jobs.get_state(step['job_id'])\n",
"                    print(state)\n",
"                    if state == 'ok':\n",
"                        # job finished\n",
"                        # all_ready = True\n",
"                        # do not need to set this. it is true\n",
"                        continue\n",
"                    else:\n",
"                        # not finished, so set to false\n",
"                        all_ready = False\n",
"                except: \n",
"                    all_ready = False\n",
"                    time.sleep(10)\n",
"print(\"done\")                "
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"for sample in samples:\n",
"    print(\"Sample: %s\" % sample)\n",
"    steps = None\n",
"    success = False\n",
"    while(not success):\n",
"        try:\n",
"            success = True\n",
"            steps = gi.workflows.show_invocation(invoked_workflows[sample]['workflow_id'], invoked_workflows[sample]['id'])['steps']\n",
"        except:\n",
"            time.sleep(10)\n",
"            success = False\n",
"    for step in steps:\n",
"        print(\"Step: %s\" % step)\n",
"        if step['workflow_step_label'] in downloads:\n",
"            print(\"Downloading step: %s\" % step['workflow_step_label'])\n",
"            outputs = None\n",
"            success = False\n",
"            while(not success):\n",
"                try:\n",
"                    success = True\n",
"                    outputs = gi.jobs.show_job(step['job_id'])['outputs']\n",
"                except:\n",
"                    time.sleep(10)\n",
"                    success = False                \n",
"            for output in outputs:\n",
"                print(\"output %s\" % output)\n",
"                if output == downloads[step['workflow_step_label']]['type']:\n",
"                        #print(step['workflow_step_label'])\n",
"                        #print(output)\n",
"                        print(filename_prefix + downloads[step['workflow_step_label']]['filename_postfix'])\n",
"                        #print (outputs[output]['id'])\n",
"                        #print (outputs[output]['src'])\n",
"                        #gi.datasets.download_dataset(outputs[output]['id'], file_path=filename_prefix + downloads[step['workflow_step_label']]['filename_postfix'], use_default_filename=False, maxwait=12000)\n",
"                        \n",
"                        success = False\n",
"                        while(not success):\n",
"                            try:\n",
"                                success = True\n",
"                                with open( filename_prefix + downloads[step['workflow_step_label']]['filename_postfix'], 'bw') as f:\n",
"                                    print(\"Writing outputid %s\" % outputs[output]['id'])\n",
"                                    dataset = gi.datasets.download_dataset(outputs[output]['id'], use_default_filename=False, maxwait=12000)\n",
"                                    f.write(dataset)\n",
"                                    #print(dataset)\n",
"                                    #f.close()\n",
"                            except:\n",
"                                time.sleep(10)\n",
"                                success = False                \n",
"\n",
"                            \n",
"print(\"DONE\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"import pandas\n",
"import time"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"frame = pandas.read_csv('8-way RIL population_RIL1_counts.txt','\\t')\n",
"frame[0:20]"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"result = frame.sort_values(['TPM'], ascending=[0])\n",
"result[0:20]"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"result = result[0:20]"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"import matplotlib.pyplot as plt;\n",
"%matplotlib inline\n",
"\n",
"figsize = [10,10] # size ~cm\n",
"\n",
"p = result.plot(x='Name',y=['TPM','NumReads'],xticks=range(0,20),figsize=figsize)\n",
"p.set_xticklabels(result.Name,rotation=90)\n",
"q = result.plot(x='Name',y='TPM',xticks=range(0,20),figsize=figsize)\n",
"q.set_xticklabels(result.Name,rotation=90)\n",
"\n",
"\n",
"plt.show()\n",
"time.sleep(10)"
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.7.3"
}
},
"nbformat": 4,
"nbformat_minor": 2
}

