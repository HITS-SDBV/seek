{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy integration through API from FAIRDOM\n",
    "\n",
    "* Upload data from list of URLs\n",
    "* Run workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioblend import galaxy\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_config = {\n",
    "    'url': 'https://usegalaxy.be',\n",
    "    'api_key': '707a42add356ba80066c1aafde3c5b9d' # make an account on the Galaxy instance and then User - Preferences - Manage API key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairdom_config = {\n",
    "    #'investigation' : '8-way RIL population', # Wolfgang\n",
    "    'investigation' : '8-way_RIL_population',# Frederik\n",
    "    \n",
    "    #'study' : 'RIL_8-way_growth_chamber',    \n",
    "    #'assay' : 'RNA_seq_E-MTAB-3965',         \n",
    "    'workflow' : 'Salmon_maize_paired' # name of the workflow, assumes there is only one with that name\n",
    "}\n",
    "\n",
    "#samples = {\n",
    "#    'RIL1' : \n",
    "#        { \n",
    "#            'forward' : 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/002/ERR1059392/ERR1059392_1.fastq.gz',\n",
    "#            'reverse' : 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/002/ERR1059392/ERR1059392_2.fastq.gz',\n",
    "#            #'phenotyping' : 'https://floppy.psb.ugent.be/index.php/s/0ZK7y1gZb26BAEg/download'\n",
    "# }\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of URLs read from the data file:\n",
      "\n",
      "SAMPLENAME\n",
      "STEP2:URL2\n",
      "STEP1:URL1\n"
     ]
    }
   ],
   "source": [
    "samples = {\n",
    "    'SAMPLENAME' : \n",
    "        { \n",
    "            'STEP1' : 'URL1',\n",
    "            'STEP2' : 'URL2',\n",
    "        }\n",
    "}\n",
    "print \"The list of URLs read from the data file:\\n\"\n",
    "\n",
    "for x in samples:\n",
    "    print (x)\n",
    "    for y in samples[x]:\n",
    "        print (y +':'+ samples[x][y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Connection to Galaxy\n",
    "'url': 'https://usegalaxy.be',\n",
    "'api_key': 'API_KEY' # make an account on the Galaxy instance and then User - Preferences - Manage API key\n",
    "\n",
    "* Info needed from FAIRDOM\n",
    "investigation : 8-way RIL population\n",
    "workflow : Salmon_maize_paired\n",
    "\n",
    "* Info on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = galaxy.GalaxyInstance(url=galaxy_config['url'], key=galaxy_config['api_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current user's information:\n",
      "\n",
      "username:wolfgang\n",
      "email:wolfgang.mueller@h-its.org\n",
      "is_admin:False\n"
     ]
    }
   ],
   "source": [
    "print (\"Current user's information:\\n\")\n",
    "current_user = gi.users.get_current_user()\n",
    "\n",
    "print (\"username:\" + current_user[\"username\"])\n",
    "print (\"email:\" + current_user[\"email\"])\n",
    "print (\"is_admin:\" + str(current_user[\"is_admin\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data and copy it to Galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I created a FAIRDOM data library where we will upload data, getting a link to it\n",
    "* I need give an accouynt access to allow to write in this folder (feature not a bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I created a FAIRDOM data library where we will upload data, getting a link to it\n",
    "#I need give an accouynt access to allow to write in this folder (feature not a bug)\n",
    "library = gi.libraries.get_libraries(name = 'FAIRDOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder with the investigation name already exist!\n"
     ]
    }
   ],
   "source": [
    "# If a folder with the investigation name already exist, \n",
    "\n",
    "root_folder = gi.libraries.get_folders(library[0]['id'])\n",
    "files = gi.libraries.show_library(library[0]['id'], contents=True)\n",
    "\n",
    "investigation_present = False\n",
    "\n",
    "investigation_library = \"\"\n",
    "\n",
    "for file in files:\n",
    "    if file['name'] == (\"/\" + fairdom_config['investigation']):\n",
    "        investigation_present = True\n",
    "        investigation_library = file['id']\n",
    "\n",
    "if not investigation_present:\n",
    "    print(\"A folder with the investigation name doesn't exist, create investigation!\")\n",
    "    investigation_library =  gi.libraries.create_folder(library[0]['id'], fairdom_config['investigation'], description=None)[0]\n",
    "else:\n",
    "    investigation_library =  gi.libraries.get_folders(library[0]['id'], name = \"/\" + fairdom_config['investigation'])[0]\n",
    "    print(\"A folder with the investigation name already exist!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLENAME\n",
      "URL2\n",
      "\n",
      "\n",
      "URL1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uploads = {}\n",
    "for sample in samples:\n",
    "    print(sample)\n",
    "    uploads[sample] = []\n",
    "    for key, file in samples[sample].items():\n",
    "            print(file)\n",
    "            print(\"\\n\")\n",
    "            # does not check if file is present\n",
    "            file_present = False\n",
    "            for avail_file in files:\n",
    "                if avail_file['name'] == (\"/\" + fairdom_config['investigation'] + \"/\" + file):\n",
    "                    print(\"file found: \")\n",
    "                    print(avail_file)\n",
    "                    print(\"\\n\")\n",
    "                    uploads[sample].append(avail_file) \n",
    "                    file_present = True\n",
    "                    break\n",
    "            if not file_present :\n",
    "                # this gives url as filename, can be changed through update, not yet implemented\n",
    "                uploaded_file = gi.libraries.upload_file_from_url(library[0]['id'], \n",
    "                     file_url = file, \n",
    "                     folder_id=investigation_library['id'], \n",
    "                     file_type='fastqsanger.gz',\n",
    "                     #file_type='auto',                                             \n",
    "                     #dbkey='?'\n",
    "                    )\n",
    "                uploads[sample].append(uploaded_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLENAME\n",
      "queued\n",
      "queued\n",
      "Waiting for upload\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9146619b0a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_yet_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waiting for upload\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The files are Ready !\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# to be improved, now waiting for all samples to be uploaded\n",
    "not_yet_ready = True\n",
    "errors = False\n",
    "while not_yet_ready:\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        for upload in uploads[sample]:\n",
    "            print(gi.libraries.show_dataset(library[0]['id'], upload['id'])['state'])\n",
    "            if gi.libraries.show_dataset(library[0]['id'], upload['id'])['state'] == 'ok':\n",
    "                not_yet_ready = False\n",
    "                # update_library_dataset(library[0]['id'], name=\"name_to_which_it_needs_to_be_changed\")\n",
    "            elif gi.libraries.show_dataset(library[0]['id'], upload['id'])['state'] == 'error':\n",
    "                not_yet_ready = False\n",
    "                errors = True\n",
    "            else: \n",
    "                not_yet_ready = True\n",
    "\n",
    "    if not_yet_ready:\n",
    "        print(\"Waiting for upload\")\n",
    "        time.sleep(60)\n",
    "            \n",
    "print(\"The files are Ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assumes a workflow with that name is present for the user\n",
    "workflows = gi.workflows.get_workflows(name = fairdom_config['workflow'], published=True)\n",
    "workflow = workflows[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoked_workflows = {}\n",
    "for sample in samples:\n",
    "    \n",
    "    # assuming order forward - reverse and only for the first pair\n",
    "    inputs = {}\n",
    "    inputs[0] = { 'src':'ld', 'id':uploads[sample][0]['id'] }\n",
    "    inputs[1] = { 'src':'ld', 'id':uploads[sample][1]['id'] }\n",
    "\n",
    "    invoked_workflow = gi.workflows.invoke_workflow(workflow['id'], \n",
    "                             inputs=inputs, \n",
    "                             import_inputs_to_history=True, \n",
    "                             history_name=sample)\n",
    "    print(\"invoked workflow...\\n\")\n",
    "    print(\"update time:\"+invoked_workflow[\"update_time\"])\n",
    "    print(\"history id:\"+invoked_workflow[\"history_id\"])\n",
    "    print(\"uuid:\"+invoked_workflow[\"uuid\"])\n",
    "    print(\"state:\"+invoked_workflow[\"state\"])\n",
    "    print(\"workflow id:\"+invoked_workflow[\"workflow_id\"])\n",
    "    print(\"model_class:\"+invoked_workflow[\"model_class\"])\n",
    "    print(\"id:\"+invoked_workflow[\"id\"])\n",
    "\n",
    "\n",
    "\n",
    "    #print(invoked_workflow)\n",
    "    invoked_workflows[sample] = invoked_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to match annotation of workflow step labels\n",
    "# assuming downloading one file per step\n",
    "downloads = {\n",
    "    'FastQC forward': {\n",
    "        'type' : 'html_file',\n",
    "        'filename_postfix' : 'fastqc_fw.zip' # zip file with a html (and other stuff) inside\n",
    "    }, \n",
    "    'FastQC reverse' : {\n",
    "        'type' : 'text_file', # essentially same output as previous one, but text version\n",
    "        'filename_postfix' : 'fastqc_rev.txt'\n",
    "    }, \n",
    "    'Salmon' : {\n",
    "        'type' : 'output_quant',\n",
    "        'filename_postfix' : 'counts.txt'\n",
    "    }\n",
    "}\n",
    "\n",
    "print \"Downloading files:\\n\"\n",
    "\n",
    "for x in downloads:\n",
    "    print (x)\n",
    "    for y in downloads[x]:\n",
    "        print (y +':'+ downloads[x][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ready = False\n",
    "\n",
    "while not all_ready:\n",
    "    time.sleep(10)\n",
    "    all_ready = True\n",
    "    for sample in samples:\n",
    "        print (sample)\n",
    "        filename_prefix = fairdom_config['investigation'] + '_' + sample + '_' # to do: link with sample name, for now hardcoded\n",
    "        #print (\"filename_prefix:\"+filename_prefix)\n",
    "        #print (str(gi.workflows.show_invocation(invoked_workflows[sample]['workflow_id'], invoked_workflows[sample]['id'])['steps']))\n",
    "        for step in gi.workflows.show_invocation(invoked_workflows[sample]['workflow_id'], invoked_workflows[sample]['id'])['steps']:\n",
    "            print(\"steps:\")\n",
    "            #print(step)\n",
    "            if step['job_id']: # input does not have job_id\n",
    "                print(gi.jobs.get_state(step['job_id']))\n",
    "                if gi.jobs.get_state(step['job_id']) == 'ok':\n",
    "                    # job finished\n",
    "                    all_ready = True\n",
    "                else:\n",
    "                    all_ready = False\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    for step in gi.workflows.show_invocation(invoked_workflows[sample]['workflow_id'], invoked_workflows[sample]['id'])['steps']:\n",
    "        if step['workflow_step_label'] in downloads:\n",
    "            outputs = gi.jobs.show_job(step['job_id'])['outputs']\n",
    "            for output in outputs:\n",
    "                if output == downloads[step['workflow_step_label']]['type']:\n",
    "                        #print(step['workflow_step_label'])\n",
    "                        #print(output)\n",
    "                        print(filename_prefix + downloads[step['workflow_step_label']]['filename_postfix'])\n",
    "                        #print (outputs[output]['id'])\n",
    "                        #print (outputs[output]['src'])\n",
    "                        #gi.datasets.download_dataset(outputs[output]['id'], file_path=filename_prefix + downloads[step['workflow_step_label']]['filename_postfix'], use_default_filename=False, maxwait=12000)\n",
    "                        \n",
    "                        with open( filename_prefix + downloads[step['workflow_step_label']]['filename_postfix'], 'bw') as f:\n",
    "                            f.write(gi.datasets.download_dataset(outputs[output]['id'], use_default_filename=False, maxwait=12000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
